{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP WORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Hasan\n"
     ]
    }
   ],
   "source": [
    "print(\"Hasan\") #Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Update branch\n"
     ]
    }
   ],
   "source": [
    "print(\"Update branch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Library\n",
    "#The OS module in python provides functions for interacting with the operating system. OS, comes under Python’s standard utility modules. This module provides a portable way of using operating system dependent functionality.\n",
    "\n",
    "#The nltk.corpus package defines a collection of corpus reader classes, which can be used to access the contents of a diverse set of corpora.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import nltk\n",
    "import nltk.corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "posix\n/home/hasan/Desktop/practice\n"
     ]
    }
   ],
   "source": [
    "print(os.name)# This function gives the name of the operating system dependent module imported.                 The following names have currently been registered: ‘posix’, ‘nt’, ‘os2’, ‘ce’,                    ‘java’ and ‘riscos’\n",
    "print(os.getcwd())#Current Working Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Punkt Sentence Tokenizer\n",
    "\n",
    "#This tokenizer divides a text into a list of sentences, by using an unsupervised algorithm to build a model for abbreviation words, collocations, and words that start sentences. It must be trained on a large collection of plaintext in the target language before it can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to /home/hasan/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This is a sample text for Natural Language Processing.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['this',\n",
       " 'is',\n",
       " 'a',\n",
       " 'sample',\n",
       " 'text',\n",
       " 'for',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " '.']"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "tokenized_text = word_tokenize(text.lower())\n",
    "tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A RegEx, or Regular Expression, is a sequence of characters that forms a search pattern.\n",
    "\n",
    "#RegEx can be used to check if a string contains the specified search pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "punctuation = re.compile(r'[,./?!:()\\'\\\"|0-9]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['this',\n",
       " 'is',\n",
       " 'a',\n",
       " 'sample',\n",
       " 'text',\n",
       " 'for',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing']"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "post_punctuation = []\n",
    "for words in tokenized_text:\n",
    "  word = punctuation.sub(\"\", words)\n",
    "  if len(word) > 0:\n",
    "    post_punctuation.append(word)\n",
    "post_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /home/hasan/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')#pre-trained English [Part-of-Speech (POS]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('this', 'DT'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('sample', 'JJ'),\n",
       " ('text', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('natural', 'JJ'),\n",
       " ('language', 'NN'),\n",
       " ('processing', 'NN')]"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "tag=nltk.pos_tag(post_punctuation)\n",
    "tag[0:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(Maxnet chunker)The maxent_ne_chunker contains two pre-trained English named entity chunkers trained on an ACE corpus ...The objective of the Automatic Content Extraction (ACE) Program was to develop extraction technology to support automatic processing of source language data (in the form of natural text and as text derived from ASR and OCR). Automatic processing, defined at that time, included classification, filtering, and selection based on the language content of the source data,\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n[nltk_data]     /home/hasan/nltk_data...\n[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n[nltk_data] Downloading package words to /home/hasan/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')# word download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Tree('S', [('this', 'DT'), ('is', 'VBZ'), ('a', 'DT'), ('sample', 'JJ'), ('text', 'NN'), ('for', 'IN'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN')])"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "entity=nltk.chunk.ne_chunk(tag)\n",
    "entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/hasan/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')# kind of language dictionary\n",
    "stop_set = stopwords.words('english')\n",
    "stop_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['sample', 'text', 'natural', 'language', 'processing']"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "a=[]\n",
    "for words in post_punctuation:\n",
    "  if words not in stop_set:\n",
    "    post_stop= words\n",
    "    a.append(post_stop)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming is the process of producing morphological variants of a root/base word. Stemming programs are commonly referred to as stemming algorithms or stemmers.\n",
    "#Porter’s Stemmer algorithm\n",
    "#Lovins Stemmer\n",
    "#Dawson Stemmer\n",
    "#Krovetz Stemmer\n",
    "#Xerox Stemmer \n",
    "#N-Gram Stemmer \n",
    "#Snowball Stemmer\n",
    "#Lancaster Stemmer (it is not work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, SnowballStemmer, LancasterStemmer\n",
    "pst = PorterStemmer()\n",
    "sbst = SnowballStemmer('english')\n",
    "lst = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "How:how\nAttendance:attend\ncrime:crime\nprivacy:privaci\nprocedure:procedur\nout:out\n"
     ]
    }
   ],
   "source": [
    "words_to_stem = ['How', 'Attendance', 'crime', 'privacy','procedure','out']\n",
    "for words in words_to_stem:\n",
    "  print(words + \":\" + pst.stem(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "How:how\nAttendance:attend\ncrime:crime\nprivacy:privaci\nprocedure:procedur\nout:out\n"
     ]
    }
   ],
   "source": [
    "words_to_stem = ['How', 'Attendance', 'crime', 'privacy','procedure','out']\n",
    "for words in words_to_stem:\n",
    "  print(words + \":\" + sbst.stem(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lancaster stemmer use kora jabe na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "How:how\nAttendance:attend\ncrime:crim\nprivacy:priv\nprocedure:proc\nout:out\n"
     ]
    }
   ],
   "source": [
    "words_to_stem = ['How', 'Attendance', 'crime', 'privacy','procedure','out']\n",
    "for words in words_to_stem:\n",
    "  print(words + \":\" + lst.stem(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/hasan/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import wordnet       # WordNet is a dictionary\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lnt = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "How:How\nAttendance:Attendance\ncrime:crime\nprivacy:privacy\nprocedure:procedure\nout:out\n"
     ]
    }
   ],
   "source": [
    "words_to_lematize = ['How', 'Attendance', 'crime', 'privacy','procedure','out']\n",
    "for words in words_to_lematize:\n",
    "  print(words + \":\" + lnt.lemmatize(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "#nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_lemmas(text):\n",
    "    for token in text:\n",
    "        print(f'{token.text:{12}} {token.pos_:{6}} {token.lemma:<{22}} {token.lemma_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "How          ADV    16331095434822636218   how\nto           PART   3791531372978436496    to\ngive         VERB   11640825575873464194   give\nattendance   NOUN   987160471729325602     attendance\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u\"How to give attendance\")\n",
    "\n",
    "show_lemmas(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Enter two space-separated words\n"
     ]
    }
   ],
   "source": [
    "import en_core_web_md\n",
    "nlp = en_core_web_md.load()  \n",
    "print(\"Enter two space-separated words\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = input() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nlp(words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "please True 5.9793315 False\ngive True 5.1312923 False\na True 5.306696 False\nsuggesition False 0.0 True\nfor True 4.8435082 False\nupdate True 6.03619 False\nSimilarity: 0.5889089\n"
     ]
    }
   ],
   "source": [
    "for token in tokens: \n",
    "    # Printing the following attributes of each token. \n",
    "    # text: the word string, has_vector: if it contains \n",
    "    # a vector representation in the model,  \n",
    "    # vector_norm: the algebraic norm of the vector, \n",
    "    # is_oov: if the word is out of vocabulary. \n",
    "    print(token.text, token.has_vector, token.vector_norm, token.is_oov) \n",
    "  \n",
    "token1, token2 = tokens[0], tokens[1] \n",
    "  \n",
    "print(\"Similarity:\", token1.similarity(token2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Generation"
   ]
  }
 ]
}